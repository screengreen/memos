# RAG‑проект по книге 

## 1) Постановка задачи 
**Цель:** получать короткие, проверяемые ответы только из оцифрованной книги по переговорам/продажам/дейтингу.
- Агент использует информацию из предоставленных источников, а не из памяти
- Ответы без фантазий: если нет факта в тексте — писать «Не нашёл в памяти»
- Retrieveal умеет возвращять фрагменты, которые покрывают весь запрос, а не его часть
- в ответе были бы цитаты или очень похожие на оригинальные куски текста
- поддерживает русский и английский, а отвечает на языке вопроса

---

## 2) План vs факт 
| Категория | Как планировал | Что получилось |
|---|---|---|
| Факты/определения | Точно, со ссылками | ✔️ Стабильно | 
| Сравнения | Баланс 2+ фрагментов | ⚠️ Может быть однобоко, видит иногда только часть фрагментов | 
| Примеры| Прямые цитаты или около копия | ⚠️ Бывает перефраз | 
| «Нет в книге» | выдача "не знаю", если нет информации | ⚠️ Не всегда | 
| Стабильность, не мешающая качеству | Похожие ответы | ⚠️ Слегка плавает | 
|Мультиязычность| Есть| ✔️ Есть|
|ответ на языке вопроса| Есть| ⚠️ есть, но иногда путается в языках|
|все retreveal работают нормально| Нет| mem OS плохо отрабатыавет|

---

## 3) Результаты оценки retrieval (все метрики лежат в ноутбуке в выводе ячейки)
Для просчёта метрик использовался датасет на 550 вопросов и ответов (`qas.pkl`).

| Метод   | Hit@1 | Hit@5 | Hit@10 | Recall@5 | Recall@20 | MRR   | nDCG@5 | nDCG@20 |
|---------|-------|-------|--------|----------|-----------|-------|--------|---------|
| BM25    | 0.481 | 0.642 | 0.705  | 0.642    | **0.769** | 0.557 | 0.569  | 0.605   |
| MemOS     | 0.079 | 0.157 | 0.194  | 0.157    | 0.250     | 0.114 | 0.118  | 0.144   |
| RRF     | 0.224 | 0.614 | 0.706  | 0.614    | **0.769** | 0.379 | 0.425  | 0.471   |
| Rerank  | **0.664** | **0.757** | **0.767** | **0.757** | **0.769** | **0.707** | **0.718** | **0.722** |

### Выводы
- **BM25** остаётся сильной базой: высокий `Recall@20` (0.769) и приличный `Hit@1` (0.481).  
- **Vec (векторный поиск)** сильно проседает по всем метрикам (Hit@1 = 0.079). Для русскоязычного корпуса это может быть признаком неудачной модели/нормализации/чункования.  
- **RRF** (BM25+Vec) даёт высокий `Recall@20` (0.769), но заметно хуже `Hit@1` (0.224), т.е. текущая смесь вредит топ-1.  
- **Rerank** уверенно лучший: максимум по `Hit@1` (0.664), `Recall@5` (0.757), `MRR` (0.707), `nDCG@20` (0.722). Переранжирование критично улучшает качество первых позиций.  

---

## 4) Гипотезы и улучшения

1) чтобы добавить больше около копий, добавить более стабильное "не знаю", повысить стабильность и сделать выбор языка ответа более точным:  
**Промпт и формат ответа** 
- Температуру снизить до **0.2–0.3**; добавить правило: «каждый пункт — с **цитатой**.  
- Улучшить информативность промпта, лучше оформить структуру подачи текста в модель. Применить все техники промпт
инжиниринга, тут думаю очень много чего можно добавить. 

2) Чтобы брать более разношерстные подходящие фрагменты:
- **MMR‑диверсификация** на топ‑N (например, N=50 -> 10–15 уникальных и непохожих кандидатов), чтобы сравнения подтягивали «обе стороны». (MMR (Maximal Marginal Relevance) выбирает кандидатов не только по релевантности к запросу, но и по **непохожести друг на друга**.  первый фрагмент — самый релевантный. Второй выбираем так, чтобы он и релевантный был, и **не повторял** первый. Дальше — то же правило.)
- может быть разбивать запрос на подзапроссы, для каждого проводить Retrieval, и брать из каждого по n/кол-во подзапроссов кандидатов

3) Улучшение reteiveal в целом (статьи на почитать, внедрить ):
- **Pseudo‑Relevance Feedback (RM3/Bo1)** поверх BM25 для добавки терминов.
- **Doc2Query / GPL**: расширить индекс псевдо‑вопросами.
- **HyDE**: сгенерировать «гипотетический ответ» по вопросу и искать его эмбеддингом — хорошо работает на сюжетных вопросах и примерах диалогов.


---

## 5) Кратко о пайплайне 
- **Индексация:** `RecursiveCharacterTextSplitter` 
- **Гибридный поиск:** mem Os search + BM25.
- **Слияние:** RRF 
- **Реранк:** `CrossEncoder("mmarco-mMiniLMv2-L12-H384-v1")` 
- **Генерация:** Mistral 
